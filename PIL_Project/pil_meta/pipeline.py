# pil_meta/pipeline.py
"""
Main orchestration pipeline for the PIL meta-engine.
Handles config loading, symbol extraction, entity graph building, linkage injection,
tag/link application, export, and governance reporting.
"""

import sys
import traceback

from pathlib import Path

from pil_meta.loaders.config_loader import load_config
from pil_meta.loaders.asset_loader import load_asset_symbols
from pil_meta.loaders.code_loader import load_code_symbols
from pil_meta.loaders.markdown_loader import load_markdown_entries

from pil_meta.builders.entity_graph_builder import build_entity_graph
from pil_meta.builders.linkage_builder import inject_call_links
from pil_meta.builders.tag_and_link_applier_builders import apply_tags_and_links
from pil_meta.builders.usage_map_builder import build_usage_map

from pil_meta.exporters.json_exporter import export_entity_graph
from pil_meta.exporters.usage_map_exporter import export_usage_map  # <-- newly added
from pil_meta.exporters.markdown_vault_exporter import export_markdown_vault
from pil_meta.exporters.md_exporter import export_entity_markdown
from pil_meta.exporters.vault_index_exporter import export_vault_index
from pil_meta.exporters.variable_usage_report_exporter import export_variable_usage_markdown
from pil_meta.utils.exceptions_reporter_utils import generate_exception_report


def run_pipeline(config_path="pilconfig.json"):
    """
    Main entry point for running the PIL meta pipeline.
    Loads config, runs all stages, and writes outputs using bulletproof absolute pathing.
    """
    try:
        # 1. Load config and resolve all paths as absolute
        config = load_config(config_path)
        print("[PIL] Loaded config with resolved paths:")
        for key in ["project_root", "journal_path", "output_dir", "docs_dir", "vault_dir", "snapshot_dir"]:
            print(f"  {key}: {config.get(key)}")

        # 2. Load asset symbols from all tracked asset directories
        asset_symbols = load_asset_symbols(config)
        print(f"âœ… Found {len(asset_symbols)} asset files.")

        # 3. Load and parse all Python source files in project_root
        code_symbols = []
        project_root = config["project_root"]
        for pyfile in Path(project_root).rglob("*.py"):
            # Optionally, filter out test or scripts folders if you wish
            code_symbols.extend(load_code_symbols(str(pyfile), project_root))
        print(f"âœ… Found {len(code_symbols)} code symbols.")

        # 4. Build the base entity graph (merge code and assets)
        entities = code_symbols + asset_symbols
        entity_graph = build_entity_graph(entities)
        print("âœ… Built entity graph.")

        # 5. Inject call linkages into the graph
        entity_graph = inject_call_links(entity_graph, project_root)
        print("âœ… Injected call linkages.")

        # 6. Apply tags and links (journal, manual tags, etc)
        entity_graph = apply_tags_and_links(entity_graph)
        print("âœ… Applied tags and links.")

        # 7. Export entity graph JSON
        export_entity_graph(entity_graph, config["output_dir"])
        print(f"âœ… Exported entity graph to {config['output_dir']}")

        # 8. Build and export the usage map as JSON
        usage_map = build_usage_map(entity_graph)
        export_usage_map(usage_map, config["output_dir"])
        print(f"âœ… Exported usage map to {config['output_dir']}/usage_map.json")

        # 9. Export Markdown vault, index, and variable usage report
        export_markdown_vault(entity_graph, config["vault_dir"])
        export_vault_index(entity_graph, config["vault_dir"])
        export_variable_usage_markdown(usage_map, str(Path(config["output_dir"]) / "variable_usage.md"))
        print(f"âœ… Exported Markdown vault and variable usage report to {config['vault_dir']} and {config['output_dir']}")

        # 10. (Optional) Export individual markdown files for code entities
        # for node in entity_graph.values():
        #     export_entity_markdown(node, config["output_dir"])  # Uncomment if needed

        # 11. Governance reporting / exceptions
        exceptions_path = str(Path(config["output_dir"]) / "function_map_exceptions.json")
        generate_exception_report(entity_graph, exceptions_path)

        print(f"âœ… Exceptions report written â†’ {config['output_dir']}/function_map_exceptions.json")

        # 12. (Optional) Load and index Markdown docs/journals
        journal_entries = load_markdown_entries(config["journal_path"])
        print(f"âœ… Loaded {len(journal_entries)} markdown journal entries.")

        print("\nðŸ“Š Project health snapshot:")
        missing_docstrings = sum(1 for n in entity_graph.values() if not n.get("docstring_present"))
        orphaned = sum(1 for n in entity_graph.values() if n.get("is_orphaned"))
        print(f"   â”œâ”€ {missing_docstrings} missing docstrings")
        print(f"   â””â”€ {orphaned} orphaned (unlinked) entities")
        print("\nâœ… Metadata pipeline complete.")

        # 13. (Optional) Snapshot step (non-fatal if missing)
        try:
            import subprocess
            subprocess.run([sys.executable, "scripts/snapshot_project.py"], check=True)
            print("ðŸ“¦ Project snapshot taken.")
        except Exception as e:
            print(f"âš ï¸ Snapshot step failed: {e}")

    except Exception:
        print("\nâŒ Pipeline failed. Full traceback below:")
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    # Default: config path is 'pilconfig.json' in this folder
    run_pipeline()
